# utils.py

def custom_tokenizer(text):
    return text.split(',')
